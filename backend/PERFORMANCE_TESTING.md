# HelloAgents æ€§èƒ½æµ‹è¯•æŒ‡å—

å®Œæ•´çš„åç«¯æ€§èƒ½æµ‹è¯•ä½“ç³»ï¼ŒåŒ…å«åŸºå‡†æµ‹è¯•ã€è´Ÿè½½æµ‹è¯•ã€å‹åŠ›æµ‹è¯•ã€æ€§èƒ½ç›‘æ§ã€‚

---

## ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æµ‹è¯•å·¥å…·](#æµ‹è¯•å·¥å…·)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ€§èƒ½åŸºå‡†æµ‹è¯•](#æ€§èƒ½åŸºå‡†æµ‹è¯•)
- [API æ€§èƒ½æµ‹è¯•](#api-æ€§èƒ½æµ‹è¯•)
- [è´Ÿè½½æµ‹è¯•](#è´Ÿè½½æµ‹è¯•)
- [æŠ¥å‘Šç”Ÿæˆ](#æŠ¥å‘Šç”Ÿæˆ)
- [æ€§èƒ½ç›®æ ‡](#æ€§èƒ½ç›®æ ‡)
- [CI/CD é›†æˆ](#cicd-é›†æˆ)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

---

## æ¦‚è¿°

HelloAgents æ€§èƒ½æµ‹è¯•ä½“ç³»æ¶µç›–:

1. **åŸºå‡†æµ‹è¯•** (Pytest-Benchmark): å®¹å™¨æ± ã€ä»£ç æ‰§è¡Œã€API ç«¯ç‚¹çš„ç²¾ç¡®æ€§èƒ½åŸºå‡†
2. **è´Ÿè½½æµ‹è¯•** (Locust): æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è´Ÿè½½ï¼Œæµ‹è¯•ç³»ç»Ÿååé‡å’Œå“åº”æ—¶é—´
3. **å‹åŠ›æµ‹è¯•** (K6): å¤šåœºæ™¯å‹åŠ›æµ‹è¯•ï¼Œè¯„ä¼°ç³»ç»Ÿæé™å’Œç¨³å®šæ€§
4. **æ€§èƒ½ç›‘æ§**: å®æ—¶ç›‘æ§å’ŒæŠ¥å‘Šç”Ÿæˆ

---

## æµ‹è¯•å·¥å…·

### 1. Pytest-Benchmark
- **ç”¨é€”**: å¾®åŸºå‡†æµ‹è¯•ï¼Œç²¾ç¡®æµ‹é‡å‡½æ•°/æ–¹æ³•æ€§èƒ½
- **ä¼˜åŠ¿**: ç»Ÿè®¡å‡†ç¡®ã€æ˜“äºé›†æˆã€è‡ªåŠ¨çƒ­èº«
- **é€‚ç”¨åœºæ™¯**: å®¹å™¨æ± æ€§èƒ½ã€ä»£ç æ‰§è¡Œå»¶è¿Ÿã€æ•°æ®åº“æŸ¥è¯¢

### 2. Locust
- **ç”¨é€”**: åˆ†å¸ƒå¼è´Ÿè½½æµ‹è¯•ï¼Œæ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸º
- **ä¼˜åŠ¿**: Python ç¼–å†™ã€Web UIã€åˆ†å¸ƒå¼æ”¯æŒ
- **é€‚ç”¨åœºæ™¯**: API è´Ÿè½½æµ‹è¯•ã€çœŸå®ç”¨æˆ·æµé‡æ¨¡æ‹Ÿ

### 3. K6
- **ç”¨é€”**: ç°ä»£åŒ–è´Ÿè½½æµ‹è¯•ï¼Œæ”¯æŒå¤šç§æµ‹è¯•åœºæ™¯
- **ä¼˜åŠ¿**: JavaScript ç¼–å†™ã€æ€§èƒ½ä¼˜å¼‚ã€åœºæ™¯ä¸°å¯Œ
- **é€‚ç”¨åœºæ™¯**: å‹åŠ›æµ‹è¯•ã€å³°å€¼æµ‹è¯•ã€æµ¸æ³¡æµ‹è¯•

---

## å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
# è¿›å…¥åç«¯ç›®å½•
cd backend

# å®‰è£… Python ä¾èµ–
pip install -r requirements.txt

# å®‰è£… K6 (å¯é€‰)
# macOS
brew install k6

# Linux
sudo apt-get install k6

# Windows
choco install k6
```

### è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶

```bash
# 1. è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
pytest tests/test_performance_benchmarks.py --benchmark-only

# 2. å¯åŠ¨åç«¯æœåŠ¡
uvicorn app.main:app --host 0.0.0.0 --port 8000

# 3. è¿è¡Œ Locust è´Ÿè½½æµ‹è¯• (æ–°ç»ˆç«¯)
locust -f locustfile.py --host=http://localhost:8000 --headless -u 50 -r 10 -t 2m

# 4. è¿è¡Œ K6 å‹åŠ›æµ‹è¯• (æ–°ç»ˆç«¯)
k6 run load-test-k6.js

# 5. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
python scripts/generate_performance_report.py
```

---

## æ€§èƒ½åŸºå‡†æµ‹è¯•

### å®¹å™¨æ± æ€§èƒ½æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰å®¹å™¨æ± åŸºå‡†æµ‹è¯•
pytest tests/test_performance_benchmarks.py::test_container_acquisition_performance --benchmark-only

pytest tests/test_performance_benchmarks.py::test_container_reset_performance --benchmark-only

pytest tests/test_performance_benchmarks.py::test_concurrent_container_acquisition --benchmark-only
```

**æ€§èƒ½ç›®æ ‡:**
- å®¹å™¨è·å–: < 100ms (å¹³å‡)
- å®¹å™¨é‡ç½®: < 250ms
- å¹¶å‘è·å–: < 500ms (10 å¹¶å‘)

### ä»£ç æ‰§è¡Œæ€§èƒ½æµ‹è¯•

```bash
# å¯¹æ¯”å®¹å™¨æ±  vs æ— å®¹å™¨æ± 
pytest tests/test_performance_benchmarks.py -k "sandbox_execution" --benchmark-only

# æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡
pytest tests/test_performance_benchmarks.py --benchmark-only --benchmark-verbose
```

**æ€§èƒ½ç›®æ ‡:**
- ä½¿ç”¨å®¹å™¨æ± : < 200ms
- ä¸ä½¿ç”¨å®¹å™¨æ± : > 1000ms
- æ€§èƒ½æå‡: 5-10x

### å¥åº·æ£€æŸ¥æ€§èƒ½æµ‹è¯•

```bash
pytest tests/test_performance_benchmarks.py -k "health_check" --benchmark-only
```

**æ€§èƒ½ç›®æ ‡:**
- å¿«é€Ÿå¥åº·æ£€æŸ¥: < 50ms
- æ·±åº¦å¥åº·æ£€æŸ¥: < 500ms

### ç”ŸæˆåŸºå‡†æŠ¥å‘Š

```bash
# ç”Ÿæˆ JSON æŠ¥å‘Š
pytest tests/test_performance_benchmarks.py --benchmark-only --benchmark-json=benchmark_results.json

# ç”Ÿæˆ HTML æŠ¥å‘Š
pytest tests/test_performance_benchmarks.py --benchmark-only --benchmark-autosave

# å¯¹æ¯”å†å²åŸºå‡†
pytest tests/test_performance_benchmarks.py --benchmark-compare --benchmark-compare-fail=mean:5%
```

---

## API æ€§èƒ½æµ‹è¯•

### è¿è¡Œ API ç«¯ç‚¹æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰ API æ€§èƒ½æµ‹è¯•
pytest tests/test_api_performance.py --benchmark-only

# æŒ‰ç»„è¿è¡Œ
pytest tests/test_api_performance.py -m api_code --benchmark-only
pytest tests/test_api_performance.py -m api_lessons --benchmark-only
pytest tests/test_api_performance.py -m api_progress --benchmark-only

# å¹¶å‘æµ‹è¯•
pytest tests/test_api_performance.py -m concurrent --benchmark-only
```

**æ€§èƒ½ç›®æ ‡:**

| ç«¯ç‚¹ | P95 ç›®æ ‡ | P99 ç›®æ ‡ |
|------|----------|----------|
| POST /api/v1/code/execute | < 300ms | < 500ms |
| GET /api/v1/lessons | < 100ms | < 200ms |
| GET /api/v1/lessons/{id} | < 50ms | < 100ms |
| POST /api/v1/progress | < 100ms | < 200ms |
| GET /api/v1/progress | < 50ms | < 100ms |

### å“åº”æ—¶é—´åˆ†å¸ƒæµ‹è¯•

```bash
# æµ‹è¯• P50/P95/P99 åˆ†å¸ƒ
pytest tests/test_api_performance.py::test_api_response_time_distribution -v
```

---

## è´Ÿè½½æµ‹è¯•

### Locust è´Ÿè½½æµ‹è¯•

#### Web UI æ¨¡å¼ (æ¨è)

```bash
# å¯åŠ¨ Locust Web UI
locust -f locustfile.py --host=http://localhost:8000

# è®¿é—® http://localhost:8089
# è®¾ç½®ç”¨æˆ·æ•°å’Œå¢é•¿ç‡ï¼Œç‚¹å‡» Start swarming
```

#### æ— å¤´æ¨¡å¼ (å‘½ä»¤è¡Œ)

```bash
# åŸºå‡†è´Ÿè½½æµ‹è¯• (10 ç”¨æˆ·, 2 åˆ†é’Ÿ)
locust -f locustfile.py --host=http://localhost:8000 --headless -u 10 -r 2 -t 2m

# è´Ÿè½½æµ‹è¯• (100 ç”¨æˆ·, 5 åˆ†é’Ÿ)
locust -f locustfile.py --host=http://localhost:8000 --headless -u 100 -r 10 -t 5m

# å‹åŠ›æµ‹è¯• (500 ç”¨æˆ·, 10 åˆ†é’Ÿ)
locust -f locustfile.py --host=http://localhost:8000 --headless -u 500 -r 50 -t 10m

# ç”ŸæˆæŠ¥å‘Š
locust -f locustfile.py --host=http://localhost:8000 --headless -u 100 -r 10 -t 5m --html=locust_report.html --csv=locust_stats
```

#### ç”¨æˆ·ç±»å‹è¯´æ˜

- **CodeExecutionUser** (70% æµé‡): é¢‘ç¹æ‰§è¡Œä»£ç çš„ç”¨æˆ·
- **BrowsingUser** (30% æµé‡): ä¸»è¦æµè§ˆè¯¾ç¨‹çš„ç”¨æˆ·
- **LearningUser**: æŒ‰å®Œæ•´å­¦ä¹ æµç¨‹æ“ä½œçš„ç”¨æˆ·
- **StressTestUser**: é«˜é¢‘å‹åŠ›æµ‹è¯•ç”¨æˆ·

### K6 è´Ÿè½½æµ‹è¯•

#### è¿è¡Œæ‰€æœ‰åœºæ™¯

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶ (åŒ…å«æ‰€æœ‰åœºæ™¯)
k6 run load-test-k6.js
```

#### è¿è¡Œç‰¹å®šåœºæ™¯

```bash
# åŸºå‡†æµ‹è¯• (10 VUs, 2 åˆ†é’Ÿ)
k6 run --env SCENARIO=baseline load-test-k6.js

# è´Ÿè½½æµ‹è¯• (é€æ­¥å¢åŠ åˆ° 100 VUs)
k6 run --env SCENARIO=load load-test-k6.js

# å‹åŠ›æµ‹è¯• (300 VUs)
k6 run --env SCENARIO=stress load-test-k6.js

# å³°å€¼æµ‹è¯• (500 VUs çªå‘)
k6 run --env SCENARIO=spike load-test-k6.js

# æµ¸æ³¡æµ‹è¯• (30 VUs, 30 åˆ†é’Ÿ)
k6 run --env SCENARIO=soak load-test-k6.js
```

#### ç”ŸæˆæŠ¥å‘Š

```bash
# ç”Ÿæˆ JSON æŠ¥å‘Š
k6 run load-test-k6.js --out json=k6_results.json

# å¯¼å‡ºæ€»ç»“
k6 run load-test-k6.js --summary-export=summary.json

# K6 Cloud (éœ€è¦è´¦å·)
k6 cloud load-test-k6.js
```

#### K6 åœºæ™¯è¯´æ˜

| åœºæ™¯ | VUs | æŒç»­æ—¶é—´ | ç›®çš„ |
|------|-----|----------|------|
| baseline | 10 | 2m | å»ºç«‹æ€§èƒ½åŸºçº¿ |
| load | 0â†’100 | 14m | æµ‹è¯•æ­£å¸¸è´Ÿè½½ |
| stress | 0â†’300 | 10m | æµ‹è¯•ç³»ç»Ÿæé™ |
| spike | 0â†’500â†’0 | 1.5m | æµ‹è¯•çªå‘æµé‡ |
| soak | 30 | 30m | æµ‹è¯•é•¿æœŸç¨³å®šæ€§ |

---

## æŠ¥å‘Šç”Ÿæˆ

### ä½¿ç”¨æŠ¥å‘Šç”Ÿæˆå™¨

```bash
# ç”Ÿæˆå®Œæ•´æŠ¥å‘Š (HTML + Markdown)
python scripts/generate_performance_report.py

# ä»…ç”Ÿæˆ HTML
python scripts/generate_performance_report.py --format html

# ä»…ç”Ÿæˆ Markdown
python scripts/generate_performance_report.py --format markdown

# æŒ‡å®šæ–‡ä»¶è·¯å¾„
python scripts/generate_performance_report.py \
  --pytest-benchmark .benchmarks/*/0001_*.json \
  --locust locust_stats.json \
  --k6 summary.json
```

### æŠ¥å‘Šå†…å®¹

æŠ¥å‘ŠåŒ…å«:
- âœ… æµ‹è¯•æ¦‚è§ˆå’Œæ‰§è¡Œæ—¶é—´
- âš ï¸ æ€§èƒ½è­¦å‘Š
- ğŸ¯ æ€§èƒ½ç›®æ ‡æ£€æŸ¥ (Pass/Fail)
- ğŸ§ª Pytest Benchmark è¯¦ç»†ç»“æœ
- ğŸ¦— Locust è´Ÿè½½æµ‹è¯•ç»Ÿè®¡
- ğŸ“ˆ K6 å‹åŠ›æµ‹è¯•æŒ‡æ ‡

### æŸ¥çœ‹æŠ¥å‘Š

```bash
# è‡ªåŠ¨åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
open performance_reports/performance_report_*.html

# æˆ–æŸ¥çœ‹ Markdown ç‰ˆæœ¬
cat performance_reports/performance_report_*.md
```

---

## æ€§èƒ½ç›®æ ‡

### å®¹å™¨æ± æ€§èƒ½

| æŒ‡æ ‡ | ç›®æ ‡ |
|------|------|
| å®¹å™¨è·å– (å¹³å‡) | < 100ms |
| å®¹å™¨è·å– (P95) | < 200ms |
| å®¹å™¨é‡ç½® | < 250ms |
| å¥åº·æ£€æŸ¥ (å¿«é€Ÿ) | < 50ms |
| å¥åº·æ£€æŸ¥ (æ·±åº¦) | < 500ms |
| å¹¶å‘è·å– (10 å¹¶å‘) | < 500ms |

### API å“åº”æ—¶é—´

| ç«¯ç‚¹ | P95 | P99 |
|------|-----|-----|
| POST /api/v1/code/execute | < 300ms | < 500ms |
| GET /api/v1/lessons | < 100ms | < 200ms |
| GET /api/v1/lessons/{id} | < 50ms | < 100ms |
| POST /api/v1/progress | < 100ms | < 200ms |

### ç³»ç»Ÿååé‡

| æŒ‡æ ‡ | ç›®æ ‡ |
|------|------|
| ååé‡ (RPS) | > 100 |
| å¹¶å‘ä»£ç æ‰§è¡Œ | > 50 |
| é”™è¯¯ç‡ | < 1% |

### èµ„æºä½¿ç”¨

| èµ„æº | é™åˆ¶ |
|------|------|
| å®¹å™¨å†…å­˜ | 128MB |
| å®¹å™¨ CPU | 50% (åŠæ ¸) |
| æ± å¤§å° | 10 (æœ€å¤§) |

---

## CI/CD é›†æˆ

### GitHub Actions é…ç½®

```yaml
name: Performance Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'  # æ¯å¤©å‡Œæ™¨ 2 ç‚¹

jobs:
  performance:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt

      - name: Run benchmark tests
        run: |
          cd backend
          pytest tests/test_performance_benchmarks.py --benchmark-only --benchmark-json=benchmark.json

      - name: Check performance regression
        run: |
          cd backend
          pytest tests/test_performance_benchmarks.py --benchmark-compare --benchmark-compare-fail=mean:10%

      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: backend/benchmark.json

      - name: Generate performance report
        run: |
          cd backend
          python scripts/generate_performance_report.py --format markdown

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('backend/performance_reports/performance_report_*.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });
```

### æ€§èƒ½é€€åŒ–æ£€æµ‹

```bash
# è®¾ç½®åŸºå‡†
pytest tests/test_performance_benchmarks.py --benchmark-only --benchmark-save=baseline

# æ£€æµ‹é€€åŒ– (å®¹å¿ 5% æ€§èƒ½ä¸‹é™)
pytest tests/test_performance_benchmarks.py --benchmark-compare=baseline --benchmark-compare-fail=mean:5%
```

---

## æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

#### 1. å®¹å™¨æ± æ€§èƒ½æœªè¾¾é¢„æœŸ

**ç—‡çŠ¶:** å®¹å™¨è·å–æ—¶é—´ > 200ms

**æ’æŸ¥æ­¥éª¤:**
```bash
# æ£€æŸ¥ Docker çŠ¶æ€
docker ps
docker stats

# æŸ¥çœ‹å®¹å™¨æ± æ—¥å¿—
tail -f backend/logs/app.log | grep "container_pool"

# æµ‹è¯•å®¹å™¨åˆ›å»ºæ—¶é—´
python backend/test_pool_performance.py
```

**è§£å†³æ–¹æ¡ˆ:**
- å¢åŠ å®¹å™¨æ± é¢„çƒ­å¤§å°
- æ£€æŸ¥ Docker èµ„æºé™åˆ¶
- ä¼˜åŒ–å®¹å™¨é•œåƒå¤§å°

#### 2. API å“åº”æ—¶é—´è¿‡æ…¢

**ç—‡çŠ¶:** P95 > 500ms

**æ’æŸ¥æ­¥éª¤:**
```bash
# æŸ¥çœ‹æ…¢æŸ¥è¯¢
pytest tests/test_api_performance.py::test_api_response_time_distribution -v

# æ£€æŸ¥æ•°æ®åº“æ€§èƒ½
pytest tests/test_api_performance.py -m database --benchmark-only
```

**è§£å†³æ–¹æ¡ˆ:**
- æ·»åŠ æ•°æ®åº“ç´¢å¼•
- å¯ç”¨æŸ¥è¯¢ç¼“å­˜
- ä¼˜åŒ– SQL æŸ¥è¯¢

#### 3. é«˜å¹¶å‘ä¸‹é”™è¯¯ç‡é«˜

**ç—‡çŠ¶:** å¹¶å‘ > 100 æ—¶é”™è¯¯ç‡ > 5%

**æ’æŸ¥æ­¥éª¤:**
```bash
# å‹åŠ›æµ‹è¯•
pytest tests/test_performance_benchmarks.py::test_pool_under_stress -m stress

# Locust å‹åŠ›æµ‹è¯•
locust -f locustfile.py --host=http://localhost:8000 --headless -u 200 -r 20 -t 5m
```

**è§£å†³æ–¹æ¡ˆ:**
- å¢åŠ å®¹å™¨æ± æœ€å¤§å¤§å°
- ä¼˜åŒ–å®¹å™¨è·å–è¶…æ—¶æ—¶é—´
- æ·»åŠ è¯·æ±‚é˜Ÿåˆ—å’Œé™æµ

#### 4. å†…å­˜æ³„æ¼

**ç—‡çŠ¶:** é•¿æ—¶é—´è¿è¡Œåå†…å­˜æŒç»­å¢é•¿

**æ’æŸ¥æ­¥éª¤:**
```bash
# æµ¸æ³¡æµ‹è¯•
k6 run --env SCENARIO=soak load-test-k6.js

# ç›‘æ§å†…å­˜
docker stats
```

**è§£å†³æ–¹æ¡ˆ:**
- æ£€æŸ¥å®¹å™¨æ˜¯å¦æ­£ç¡®æ¸…ç†
- ä¼˜åŒ–å®¹å™¨æ± ç©ºé—²å›æ”¶
- æ·»åŠ å®šæœŸé‡å¯æœºåˆ¶

### æ€§èƒ½åˆ†æå·¥å…·

```bash
# ä½¿ç”¨ py-spy è¿›è¡Œæ€§èƒ½åˆ†æ
pip install py-spy
py-spy record -o profile.svg -- python -m pytest tests/test_performance_benchmarks.py

# ä½¿ç”¨ memory_profiler
pip install memory_profiler
python -m memory_profiler backend/app/container_pool.py
```

---

## æœ€ä½³å®è·µ

### 1. å®šæœŸè¿è¡Œæ€§èƒ½æµ‹è¯•

- âœ… æ¯æ¬¡ PR è¿è¡ŒåŸºå‡†æµ‹è¯•
- âœ… æ¯æ—¥è¿è¡Œå®Œæ•´è´Ÿè½½æµ‹è¯•
- âœ… æ¯å‘¨è¿è¡Œæµ¸æ³¡æµ‹è¯•
- âœ… å‘å¸ƒå‰è¿è¡Œå‹åŠ›æµ‹è¯•

### 2. å»ºç«‹æ€§èƒ½åŸºçº¿

```bash
# ä¿å­˜æ€§èƒ½åŸºçº¿
pytest tests/test_performance_benchmarks.py --benchmark-only --benchmark-save=v1.0.0

# å¯¹æ¯”æ–°ç‰ˆæœ¬
pytest tests/test_performance_benchmarks.py --benchmark-compare=v1.0.0
```

### 3. ç›‘æ§å…³é”®æŒ‡æ ‡

- å“åº”æ—¶é—´ (P50/P95/P99)
- ååé‡ (RPS)
- é”™è¯¯ç‡
- èµ„æºä½¿ç”¨ (CPU/å†…å­˜)
- å®¹å™¨æ± çŠ¶æ€

### 4. æ€§èƒ½ä¼˜åŒ–ä¼˜å…ˆçº§

1. **é«˜ä¼˜å…ˆçº§**: P95 > ç›®æ ‡ 2x
2. **ä¸­ä¼˜å…ˆçº§**: P95 > ç›®æ ‡ 1.5x
3. **ä½ä¼˜å…ˆçº§**: P95 > ç›®æ ‡ 1.2x

---

## å‚è€ƒèµ„æº

- [Pytest-Benchmark æ–‡æ¡£](https://pytest-benchmark.readthedocs.io/)
- [Locust æ–‡æ¡£](https://docs.locust.io/)
- [K6 æ–‡æ¡£](https://k6.io/docs/)
- [Docker æ€§èƒ½æœ€ä½³å®è·µ](https://docs.docker.com/config/containers/resource_constraints/)

---

**ç»´æŠ¤è€…:** HelloAgents Performance Team
**æœ€åæ›´æ–°:** 2026-01-08
